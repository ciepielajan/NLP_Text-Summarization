{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_0_Text Summarizaton_Word_Frequency.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+yI28FLWo/acRpnTvEWwp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ciepielajan/NLP_Text-Summarization/blob/main/3_0_Text_Summarizaton_Word_Frequency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRGe1jY4n7DW"
      },
      "source": [
        "3_0_Text Summarizaton_Word_Frequency.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsC9vKJPfQQq"
      },
      "source": [
        "`pobranie bibliotek`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHsZBk-PcITs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6225b714-c876-4bd0-c8b9-cc22ff11d245"
      },
      "source": [
        "import pandas as pd\n",
        "# import math\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvrcXJ4ec_62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82a7a50-5394-4bcf-b465-8af5343ef5aa"
      },
      "source": [
        "!pip -q  install wikipedia    # -q = quite (hide output)\n",
        "import wikipedia"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvGcyzS3fiCB"
      },
      "source": [
        "`surowy tekst`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUgA9WYZdjHC"
      },
      "source": [
        "text_row = wikipedia.page(\"Machine Learing\").content\n",
        "# text_row"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTGEEppPeVap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73be218e-749a-45ae-f385-52a4c109ac89"
      },
      "source": [
        "print(\"format: \", type(text_row))\n",
        "print(\"ilość znaków: \", len(text_row))\n",
        "print(\"ilość słow: \", len(text_row.split(\" \")))\n",
        "print(\"ilość zdań: \", len(sent_tokenize(text_row)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "format:  <class 'str'>\n",
            "ilość znaków:  45879\n",
            "ilość słow:  6956\n",
            "ilość zdań:  263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdG3zCWsfmVd"
      },
      "source": [
        "`oczyszczenie tekstu`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMKc60xAgPvb"
      },
      "source": [
        "> wikipedia formatuje paragrafy wg wzorca:\n",
        "\n",
        "'=== JAKAŚ TREŚĆ ==='\n",
        "\n",
        "W pierwszej kolejności wyszukajmy wszystkie paragrafy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY9mJm3GpYxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1a1372-dea2-4f2a-c54c-28931486687c"
      },
      "source": [
        "wzorzec = r\"\\=+\\s+[\\w\\s\\-]+\\=+\"\n",
        "print(\"znalezionych wystąpień: \", len(re.findall(wzorzec,text_row)))\n",
        "print(re.findall(wzorzec,text_row))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "znalezionych wystąpień:  46\n",
            "['== Overview ==', '=== Machine learning approaches ===', '== History and relationships to other fields ==', '=== Artificial intelligence ===', '=== Data mining ===', '=== Optimization ===', '=== Generalization ===', '=== Statistics ===', '== Theory ==', '== Approaches ==', '=== Types of learning algorithms ===', '==== Supervised learning ====', '==== Unsupervised learning ====', '==== Semi-supervised learning ====', '==== Reinforcement learning ====', '==== Self learning ====', '==== Feature learning ====', '==== Sparse dictionary learning ====', '==== Anomaly detection ====', '==== Robot learning ====', '==== Association rules ====', '=== Models ===', '==== Artificial neural networks ====', '==== Decision trees ====', '==== Support-vector machines ====', '==== Regression analysis ====', '==== Bayesian networks ====', '==== Genetic algorithms ====', '=== Training models ===', '==== Federated learning ====', '== Applications ==', '== Limitations ==', '=== Bias ===', '== Model assessments ==', '== Ethics ==', '== Hardware ==', '== Software ==', '=== Free and open-source software ===', '=== Proprietary software with free and open-source editions ===', '=== Proprietary software ===', '== Journals ==', '== Conferences ==', '== See also ==', '== References ==', '== Further reading ==', '== External links ==']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZV91PA8ewJ4"
      },
      "source": [
        "text = re.sub(wzorzec, \" \",text_row) # usuń paragrafy\n",
        "text = re.sub(r'\\n+', \" \",text)  # usuń znaki nowej linii \n",
        "text = re.sub(r'\\s{2,}', \" \",text) # usuń wielokrotności spacji\n",
        "text = text.strip() # usunięcie pierwszej i ostatniej spacji\n",
        "# text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5AsyvEVOpQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b0b3c1-c167-458e-f947-a57b51aa18b5"
      },
      "source": [
        "print(\"format: \", type(text))\n",
        "print(\"ilość znaków: \", len(text))\n",
        "print(\"ilość słow: \", len(text.split(\" \")))\n",
        "print(\"ilość zdań: \", len(sent_tokenize(text)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "format:  <class 'str'>\n",
            "ilość znaków:  44241\n",
            "ilość słow:  6603\n",
            "ilość zdań:  263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMoz5HYzS1C-"
      },
      "source": [
        "`Word_Frequency`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ2diiVkB1id"
      },
      "source": [
        "`1 Sentence Tokenize`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHr08Dabogf0"
      },
      "source": [
        "def _create_frequency_table(text_string) -> dict:\n",
        "    \"\"\"\n",
        "    we create a dictionary for the word frequency table.\n",
        "    For this, we should only use the words that are not part of the stopWords array.\n",
        "    Removing stop words and making frequency table\n",
        "    Stemmer - an algorithm to bring words to its root word.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "    stopWords = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text_string)\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    freqTable = dict()\n",
        "    for word in words:\n",
        "        word = ps.stem(word)\n",
        "        if word in stopWords:\n",
        "            continue\n",
        "        if word in freqTable:\n",
        "            freqTable[word] += 1\n",
        "        else:\n",
        "            freqTable[word] = 1\n",
        "\n",
        "    return freqTable"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvy55tHpogdR"
      },
      "source": [
        "def _score_sentences(sentences, freqTable) -> dict:\n",
        "    \"\"\"\n",
        "    score a sentence by its words\n",
        "    Basic algorithm: adding the frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "\n",
        "    sentenceValue = dict()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        word_count_in_sentence = (len(word_tokenize(sentence)))\n",
        "        word_count_in_sentence_except_stop_words = 0\n",
        "        for wordValue in freqTable:\n",
        "            if wordValue in sentence.lower():\n",
        "                word_count_in_sentence_except_stop_words += 1\n",
        "                if sentence[:10] in sentenceValue:\n",
        "                    sentenceValue[sentence[:10]] += freqTable[wordValue]\n",
        "                else:\n",
        "                    sentenceValue[sentence[:10]] = freqTable[wordValue]\n",
        "\n",
        "        if sentence[:10] in sentenceValue:\n",
        "            sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] / word_count_in_sentence_except_stop_words\n",
        "\n",
        "        '''\n",
        "        Notice that a potential issue with our score algorithm is that long sentences will have an advantage over short sentences. \n",
        "        To solve this, we're dividing every sentence score by the number of words in the sentence.\n",
        "        \n",
        "        Note that here sentence[:10] is the first 10 character of any sentence, this is to save memory while saving keys of\n",
        "        the dictionary.\n",
        "        '''\n",
        "\n",
        "    return sentenceValue"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BOe3SKlogan"
      },
      "source": [
        "def _find_average_score(sentenceValue) -> int:\n",
        "    \"\"\"\n",
        "    Find the average score from the sentence value dictionary\n",
        "    :rtype: int\n",
        "    \"\"\"\n",
        "    sumValues = 0\n",
        "    for entry in sentenceValue:\n",
        "        sumValues += sentenceValue[entry]\n",
        "\n",
        "    # Average value of a sentence from original text\n",
        "    average = (sumValues / len(sentenceValue))\n",
        "\n",
        "    return average"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZF6WxMCogT3"
      },
      "source": [
        "def _generate_summary(sentences, sentenceValue, threshold):\n",
        "    sentence_count = 0\n",
        "    summary = ''\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] >= (threshold):\n",
        "            summary += \" \" + sentence\n",
        "            sentence_count += 1\n",
        "\n",
        "    return summary"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jL0J-YXpAcI"
      },
      "source": [
        "`Wywołanie wszystkich funkcji`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQBJL6DfnOdE"
      },
      "source": [
        "def run_summarization(text):\n",
        "    # 1 Create the word frequency table\n",
        "    freq_table = _create_frequency_table(text)\n",
        "\n",
        "    '''\n",
        "    We already have a sentence tokenizer, so we just need \n",
        "    to run the sent_tokenize() method to create the array of sentences.\n",
        "    '''\n",
        "\n",
        "    # 2 Tokenize the sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # 3 Important Algorithm: score the sentences\n",
        "    sentence_scores = _score_sentences(sentences, freq_table)\n",
        "\n",
        "    # 4 Find the threshold\n",
        "    threshold = _find_average_score(sentence_scores)\n",
        "\n",
        "    # 5 Important Algorithm: Generate the summary\n",
        "    summary = _generate_summary(sentences, sentence_scores, 1.6 * threshold)\n",
        "\n",
        "    return summary"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "kEN-zdeKnlJM",
        "outputId": "b2dde701-b51e-49fd-cb93-effceea32815"
      },
      "source": [
        "summarization = run_summarization(text)\n",
        "summarization"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. Some statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning. If the complexity of the model is increased in response, then the training error decreases. The data is known as training data, and consists of a set of training examples. The algorithms, therefore, learn from test data that has not been labeled, classified or categorized. In machine learning, the environment is typically represented as a Markov decision process (MDP). In supervised feature learning, features are learned using labeled input data. It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. In machine learning, genetic algorithms were used in the 1980s and 1990s. Usually, machine learning models require a lot of data in order for them to perform well.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCnzorCmFSJp"
      },
      "source": [
        "result = {\n",
        "  \"id\":\"3_0\",\n",
        "  \"ilosc znakow\": len(summarization),\n",
        "  \"ilosc slow\": len(summarization.split(\" \")),\n",
        "  \"ilosc zdan\": len(sent_tokenize(summarization))\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXkZbDKkBMpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac63151c-5ef2-481f-bbdc-b840ec63ea3d"
      },
      "source": [
        "print(pd.DataFrame.from_dict(result, orient='index').T.set_index(\"id\").to_markdown())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   id |   ilosc znakow |   ilosc slow |   ilosc zdan |\n",
            "|-----:|---------------:|-------------:|-------------:|\n",
            "|  3_0 |            966 |          153 |           10 |\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}